#1) Import libraries, add timer, create SQL database
    
#1a) Import libraries + Start Timer
import urllib.request
from bs4 import BeautifulSoup as bs4
import re
import time
import sqlite3

start_time = time.time()

#1b) Create database
conn = sqlite3.connect("file1.sqlite")
cur = conn.cursor()
cur.execute('''CREATE TABLE IF NOT EXISTS Pages (
            url TEXT UNIQUE,visit INTEGER)''')
conn.close()

#2) Define initial URL, add into database with visit column value set to 0
url = "http://www.ucla.edu/"
conn = sqlite3.connect("file1.sqlite")
cur = conn.cursor()
cur.execute('INSERT OR IGNORE INTO Pages (url, visit) VALUES (?,?)', (url,0))
conn.commit()
cur.execute('SELECT url FROM Pages WHERE visit = 0 LIMIT 1')
row = cur.fetchone()



#Loop- Opens url, reads, pulls links, adds link to database
    #Changes url visit to 1, finds next link where visit = 0, starts over 
while row is not None:
    url = row[0]
    print(url)
    doc = urllib.request.urlopen(url)
    html = doc.read().decode()
    links = re.findall('href="(http://.*?ucla.edu.*?)"', html)
    for link in links: 
        content_type = doc.info().get_content_type()
        if content_type != 'text/html':
            pass
        else:
            idx = link.find(".edu/")
            link = link[:(idx+5)]
            conn = sqlite3.connect("file1.sqlite")
            cur = conn.cursor()
            cur.execute('INSERT OR IGNORE INTO Pages (url, visit) VALUES (?,?)', (link,0))
            conn.commit()
    #Print database
    conn = sqlite3.connect("file1.sqlite")
    cur = conn.cursor()
    cur.execute('UPDATE Pages SET visit = 1 WHERE url =?', (url,))
    conn.commit()
    conn = sqlite3.connect("file1.sqlite")
    cur = conn.cursor()
    cur.execute('SELECT url FROM Pages WHERE visit = 0 LIMIT 1')
    row = cur.fetchone()

cur.execute('SELECT * from Pages')
for r in cur:
    print(r)
cur.close()


#Timer Output
print("My program took", time.time() - start_time, "seconds to run")

